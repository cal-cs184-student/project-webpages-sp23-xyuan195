<html>
	<head>
    <link rel="stylesheet" type="text/css" href="semantic/semantic.min.css">
    <script
        src="https://code.jquery.com/jquery-3.1.1.min.js"
        integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="
        crossorigin="anonymous"></script>
    <script src="semantic/semantic.min.js"></script>
    <title>Assignment 3-1 Write-up (xyuan195)</title>
	</head>
	<body>
  <div class="ui container">
    <div class="ui center aligned container">
      <br>
      <h1>Assignment 3-1 (Pathtracer 1) Write-up</h1>
      <h4>Author: Xiaoyuan Zhu (m195@berkeley.edu)</h4>
    </div>

    <h2>Overview</h2>
    <p>
      In this assignment, I practiced on how to perform ray tracing, global illumination, and adaptive sampling. I explored
      different sampling techniques for direct lighting function, also compared the effects of different parameters on
      global illumination.
    </p>
    <p>
      Online version of this write-up is hosted at:
      <a href="https://cal-cs184-student.github.io/project-webpages-sp23-xyuan195/proj3-1/index.html">
        https://cal-cs184-student.github.io/project-webpages-sp23-xyuan195/proj3-1/index.html
      </a>
    </p>

    <h2>Tasks Breakdown</h2>

    <h3>Part 1: Ray Generation and Scene Intersection</h3>
    <h4>[Part 1] Walk Through on Implementation Details</h4>
    <p>
      To generate ray from camera perspective, I need to transform the object coordinates to the world coordinates.
      I implement the transform by first scaling the coordinates to the same size as in camera coordinates, then
      translate (move) the center of the rectangle to its position in world coordinates.
    </p>
    <p>
      First, I calculate two variables: <b>double tan_h = tan(radians(hFov) * 0.5)</b> and
      <b>double tan_v = tan(radians(vFov) * 0.5)</b>.
    </p>
    <p>
      Then the scale matrix is <b>{ 2 * tan_h, 0, 0, 0, 2 * tan_v, 0, 0, 0, 1 }</b>, and the translate matrix is
      <b>{ 1, 0, -tan_h, 0, 1, -tan_v, 0, 0, 1 }</b>.
    </p>
    <p>Then I calculate the camera position as <b>translate * scale * Vector3D{x, y, 1}</b></p>.
    <p>
      Next, I get the direction of the ray as <b>Vector3D d = c2w * Vector3D{camera_pos[0], camera_pos[1], -1}</b>. Then
      I normalize it by calling <b>d.normalize()</b> to make it ready to be used in the Ray constructor.
    </p>
    <p>
      Lastly, I construct the ray by <b>Ray(pos, d)</b>, and set its <b>min_t</b> to <b>nClip</b> and its <b>max_t</b>
      to <b>fClip</b>.
    </p>

    <h4>[Part 1] Explanation of the Triangle Intersection Algorithm</h4>
    <p>
      I create a function <b>moller_trumbore</b> to use the Moller Trumbore formula. And the intersection is the first
      elements of the Vector3D result.
    </p>
    <p>
      Then I compare the calculated t with r.min_t and r.max_t. If <b>t</b> is out of the range, then there is no intersection.
    </p>
    <p>
      Then I get the coordinate of the intersection by <b>r.o + t * r.d</b>. Then I calculate its barycentric coordinates
      using triangle areas.
    </p>
    <p>
      After I get the barycentric coordinates of the hit point, I check all its coordinates. If any of them is out of range
      [0, 1], or the sum of these 3 coordinates is bigger than 1, I consider this hit point is outside the triangle.
      Otherwise, I set <b>r.max_t</b> to the calculated t, and return true.
    </p>

    <h4>[Part 1] Some Images with Normal Shading</h4>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part1-spheres.png">
          <h5 class="ui center aligned container">CBspheres_lambertian.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part1-empty.png">
          <h5 class="ui center aligned container">CBempty.dae</h5>
        </div>
      </div>
    </div>

    <h3>Part 2: Bounding Volume Hierarchy</h3>

    <h4>[Part 2] Walk Through on BVH Construction Algorithm</h4>
    <p>
      First, I iterate through all primitives in the scene. I keep track of the total number of primitives, the max and min
      of each coordinates of the current BBox, and a new vector of Primitives which will be used in later sorting and
      splitting.
    </p>
    <p>
      After the loop, I construct the BVHNode instance using the BBox instance.
      if the total number of primitives is less than <b>max_leaf_size</b>, I set <b>node->start</b> to
      the input start parameter, and <b>node->end</b> to the input end parameter. And just return the BVHNode instance.
      This is the base case of the recursion.
    </p>
    <p>
      If we have more primitives than max_leaf_size, I then calculate the delta of min and max values of all 3 coordinates.
      Next, I compare the calculated 3 deltas, and choose the biggest one to use as the axis to sort the primitives, based
      on their centroid values.
    </p>
    <p>
      After the sorting, I recursively call <b>construct_bvh</b> for the first half and second half of the sorted primitives,
      and assign the result of the first half to <b>node->l</b>, and the result of the second half to <b>node->r</b>.
    </p>
    <p>
      Lastly, I free the allocated vector, and return node.
    </p>
    <h4>[Part 2] Images with BVH Acceleration</h4>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part2-maxplanck.png">
          <h5 class="ui center aligned container">maxplanck.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part2-CBlucy.png">
          <h5 class="ui center aligned container">CBlucy.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part2-teapot.png">
          <h5 class="ui center aligned container">teapot.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part2-peter.png">
          <h5 class="ui center aligned container">peter.dae</h5>
        </div>
      </div>
    </div>

    <h4>[Part 2] Rendering Time Comparison between with and without BVH Acceleration</h4>
    <p>
      Rendering time with BVH acceleration is much faster than the one without it. On my local machine, it took 0.0799
      seconds to render cow.dae with BVH acceleration, and 3.9152 seconds without it.
    </p>

    <h3>Part 3: Direct Illumination</h3>

    <h4>[Part 3] Walk Through on Implementations of the Direct Lighting Function</h4>

    <p>
      Both implementations of direct illumination function uses zero-bound illumination. So I'll briefly describe how it
      works in my implementation. In function <b>zero_bounce_radiance</b> function, I check the emission of the intersection
      by calling <b>isect.bsdf->get_emission()</b>. Then I calculate its norm2. If it is smaller than <b>0.0001</b> (an
      arbitrary small float number), I consider it is not a light source and return a Vector3D with all 0 values. Otherwise,
      this is a light source and I return the emission value directly.
    </p>
    <p>
      For direct illumination with uniform hemisphere sampling, I create a loop with max iteration as <b>num_samples</b>.
      Inside the loop, first I take a sample <b>sample_o</b> using <b>hemisphereSampler->get_sample()</b>. Its resulting Vector３D value
      is in object coordinates. I then calculate its world coordinates value <b>sample_w</b> by <b>o2w * sample_o</b>.
      Then I need to normalize <b>sample_w</b> by calling <b>sample_w.normalize()</b>. Secondly, I create a ray using
      <b>hit_p</b> as the origin and normalized <b>sample_w</b> as the direction, and set its min_t to <b>EPS_F</b>. Then
      I check whether this is any intersection between this new ray and the objects in the scene by calling
      <b>bvh->intersect(ray_from_hit_p, &light_isect)</b>. If the result is false, I just skip this sample and continue
      the loop. Otherwise, the <b>light_isect</b> variable will be populated with the intersection information of the new
      ray. Because we only care about direct illumination in this function, so we must make sure the new intersection is
      a light source. So I get the Li value by <b>light_isect.bsdf->get_emission()</b>，and compare all its cooridates
      with EPS_F. If all of them are smaller than EPS_F, then this is not a light source. I just skip this sample and
      continue the loop. Otherwise, I get the <b>brdf</b> of this light source by calling <b>isect.bsdf->f(w_out, -sample_o)</b>,
      and get the cosine theta by calculating the dot product of the intersect normal and <b>sample_w</b> (in world coordinates).
      The <b>pdf</b> of any ray in uniformly sampled hemisphere is <b>0.5 / PI</b>. So I accumulate <b>L_out</b> with
      <b>(brdf * Li * cos) / pdf</b>. After exiting the loop, I return the averaged L_out by calling <b>L_out / num_samples</b>。
    </p>
    <p>
      For direct illumination with importance sampling, I loop through all lights in the scene. Inside of the loop,
      I need to get the sample size of the light source. If the light is a point light, the sample size is <b>1</b>; otherwise,
      the sample size is <b>ns_area_light</b>. Then, I create an intermediate Vector3D variable <b>L_inter</b>, which is
      the accumulator of the radiance of all samples of this light. Then I create an inner loop to loop through the sample_size.
      In each of the inner iteration, I call <b>light->sample_L</b> to take a sample from the light to the hit point.
      This function will populate 3 variables: <b>wi</b>, <b>distToLight</b>, and <b>pdf</b>. Next, I calculate the
      value of <b>wi</b> in object coordinates and store it in <b>wi_o</b>. Here I check the z coordinate of <b>wi_o</b>,
      if it is less than 0, this means the light source is behind a surface. I just skip this sample and continue the loop.
      Otherwise, I continue the processing. Next, I create a new ray using <b>hit_p</b> as the origin, and the <b>wi</b>
      (in world coordinates) as the direction. And I set its <b>min_t</b> to <b>EPS_F</b>, and <b>max_t</b> to
      <b>distToLight - EPS_F</b>. Then I check whether there is any intersection between this new ray and objects in the
      scene by calling <b>bvh->intersect(ray_from_hit_p, &light_isect)</b>. If its result is false, I just skip this sample
      and continue the loop. Otherwise, similar to uniform hemisphere sampling, I get the <b>brdf</b> of the light source
      by calling <b>isect.bsdf->f(w_out, -wi_o)</b>, and get the cosine theta by calculating the dot product between the
      intersection normal and <b>wi</b>. Then I accumulate <b>L_inter</b> by <b>(brdf * Li * cos) / pdf</b>. After I exit
      the inner loop, I accumulate <b>L_out</b> by <b>L_inter / sample_size</b> (sample_size is the total number of samples
      of this light source). Finally, after I exit the outer loop, I return <b>L_out / scene->lights.size()</b> to the
      caller.
    </p>

    <h4>[Part 3] Images with Both Implementations of the Direct Lighting Function</h4>

    <div class="ui info message">
      All below images are generated with sample rate per pixel as 16, and 8 light rays.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part3-bunney-H.png">
          <h5 class="ui center aligned container">Uniform Hemisphere Sampling for CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part3-bunney-D.png">
          <h5 class="ui center aligned container">Importance Sampling for CBbunny.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part3-spheres-H.png">
          <h5 class="ui center aligned container">Uniform Hemisphere Sampling for CBspheres_lambertian.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part3-spheres-D.png">
          <h5 class="ui center aligned container">Importance Sampling for CBspheres_lambertian.dae</h5>
        </div>
      </div>
    </div>

    <h4>[Part 3] Noise Comparison between Both Implementations of the Direct Lighting Function</h4>

    <div class="ui info message">
      All below images are generated with sample rate per pixel as 1.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part3-bunney-l1.png">
          <h5 class="ui center aligned container">1 Light Ray</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part3-bunney-l4.png">
          <h5 class="ui center aligned container">4 Light Rays</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part3-bunney-l16.png">
          <h5 class="ui center aligned container">16 Light Rays</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part3-bunney-l64.png">
          <h5 class="ui center aligned container">64 Light Rays</h5>
        </div>
      </div>
    </div>

    <h4>[Part 3] Comparison between Both Implementations of the Direct Lighting Function</h4>
    <p>
      In uniform hemisphere sampling, we cannot render point light sources because when we calculate the intersection of
      the new ray, point light sources will be ignored or skipped. The overall imaged generated by uniform hemisphere
      sampling is also much noisier than the ones using importance sampling in most of the cases, because a lot of samples
      in uniform hemisphere sampling ends up being dropped because they are not from a light source.
    </p>

    <h3>Part 4: Global Illumination</h3>

    <h4>[Part 4] Walk Through on Implementation of the Indirect Lighting Function</h4>
    <p>
      To support indirect lighting function, I first implemented <b>DiffuseBSDF::sample_f</b> function to take a sample
      by a given outgoing light direction, and store the sampled incoming light direction to variable <b>wi</b> and its
      pdf to variable <b>pdf</b>. To do this, I first call <b>sampler.get_sample()</b> to get a sample, and then plug it
      in function <b>f</b> in Part 3 (along with the outgoing light direction <b>wo</b>) to get the bsdf, which is the
      return value. But before I return this value directly, I copy the sampled Vector3D to the input <b>wi</b> parameter,
      and copy the hardcoded <b>1 / PI</b> to the input <b>pdf</b> parameter, so that they will be propagated to the caller. At last,
      I return the calculated <b>bsdf</b> value.
    </p>
    <p>
      Having <b>sample_f</b> function ready, I can start the implementation of <b>PathTracer::at_least_one_bounce_radiance</b>
      function. First of all, I check the depth of the incoming ray object: if it is equal to 0, that means we've reached
      the max ray depth, I just return <b>L_out</b> directly. This is the base case of this recursion function. If the
      ray depth is bigger than 0, we can continue the process. Firstly, I add <b>one_bounce_radiance(r, isect)</b> to
      <b>L_out</b>.
    </p>
    <p>
      Then, I take a sample using the outgoing light direction <b>w_out</b> by calling <b>sample_f</b> function we created.
      This will give us a incoming light direction <b>wi</b> and its pdf <b>pdf</b>. We will use this sampled incoming light
      direction to construct the shadow ray (the ray from the current hit point to the sampled direction). To do this,
      first I need to convert <b>wi</b> in the object coordinates to <b>wi_w</b> in the world coordinates by calling
      <b>auto wi_w = o2w * wi</b>; then I need to normalize this <b>wi_w</b> Vector3D by calling <b>wi_w.normalize()</b>;
      lastly, the new shadow ray will be <b>{ hit_p, wi_w }</b> (origin as hit_p, and direction as wi_w). I also need to
      set the <b>min_t</b> of this new ray to <b>EPS_F</b>.
    </p>
    <p>
      With this new shadow ray in hand, I check whether there's any intersection with it in the scene by calling
      <b>bvh->intersect(next_r, &intersection)</b>. If the result is false, that means there's no intersection with this
      new shadow ray, I just return <b>L_out</b> directly. Otherwise, I continue the process with the new intersection
      value stored in <b>intersection</b> variable.
    </p>
    <p>
      Now, I need to use Russian Roulette algorithm to continue the recursion. Firstly, I created a new function
      <b>PathTracer::get_continuation_probability</b>, which will be used to calculate the continuation probability (cpdf)
      of the algorithm. It takes sampled <b>brdf</b> Vector3D variable, calculates the <b>norm2</b> value, and then
      calculates the percentile by <b>(3 - norm) / 3</b>, then return <b>0.3 + percentage * (0.4 - 0.3)</b>. Basically,
      this function will return a value between 0.3 and 0.4 proportional to the normal of the sampled brdf.
    </p>
    <p>
      After I get the continuation probability (cpdf) from the above function, I plug it in <b>coin_flip</b> function
      to randomly decide whether to continue the recursion or not. If the result of <b>coin_flip</b> is false, I just
      skip the recursion call and return <b>L_out</b> directly. Otherwise, I continue the process.
    </p>
    <p>
      As to continue the recursion, I firstly calculate the cosine theta by calculating the dot product of the intersection
      normal and the incoming light direction in world coordinates <b>dot(isect.n, wi_w)</b>, then I update the depth
      of the new shadow ray to <b>r.depth - 1</b> for next recursion call, so that we can terminate the calculation by
      <b>max_ray_depth</b>. Then I recursively call <b>at_least_one_bounce_radiance</b> with the new shadow ray and the
      new intersection, and plug in its result in formula <b>at_least_one_bounce_radiance(next_r, intersection) * brdf * cos / pdf / cpdf</b>.
      Then I add the final result to <b>L_out</b>. This concludes the implementation of
      <b>at_least_one_bounce_radiance</b> function.
    </p>
    <p>
      Then I modify <b>est_radiance_global_illumination</b> function to use <b>at_least_one_bounce_radiance</b> function.
      The final <b>L_out</b> is calculated as <b>zero_bounce_radiance(r, isect) + at_least_one_bounce_radiance(r, isect)</b>.
    </p>
    <p>
      Finally, I need to modify <b>raytrace_pixel</b> function. For each sample ray, I set its depth to <b>max_ray_depth</b>,
      such that we can terminate the recursion call of <b>at_least_one_bounce_radiance</b> function if the max ray depth
      is reached.
    </p>

    <h4>[Part 4] Images Rendered with Global Illumination</h4>
    <div class="ui info message">
      All below images are generated with sample rate per pixel as 1024, and 4 light rays.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bench_demo.png">
          <h5 class="ui center aligned container">bench.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_dragon_demo.png">
          <h5 class="ui center aligned container">dragon.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_demo.png">
          <h5 class="ui center aligned container">CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_blob_demo.png">
          <h5 class="ui center aligned container">blob.dae</h5>
        </div>
      </div>
    </div>

    <h4>[Part 4] Comparison between Direct and Indirect Illumination</h4>
    <div class="ui info message">
      All below images are generated with sample rate per pixel as 1024, and 4 light rays.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_direct.png">
          <h5 class="ui center aligned container">Direct Illumination for CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_indirect.png">
          <h5 class="ui center aligned container">Indirect Illumination for CBbunny.dae</h5>
        </div>
      </div>
    </div>
    <h4>[Part 4] max_ray_depth Comparisons</h4>
    <div class="ui info message">
      All below images are generated with Russian Roulette enabled and sample rate per pixel as 1024.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_m0.png">
          <h5 class="ui center aligned container">Max Ray Depth 0 for CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_m1.png">
          <h5 class="ui center aligned container">Max Ray Depth 1 for CBbunny.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_m2.png">
          <h5 class="ui center aligned container">Max Ray Depth 2 for CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_m3.png">
          <h5 class="ui center aligned container">Max Ray Depth 3 for CBbunny.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_bunny_m100.png">
          <h5 class="ui center aligned container">Max Ray Depth 100 for CBbunny.dae</h5>
        </div>
      </div>
    </div>
    <h4>[Part 4] sample-per-pixel Comparisons</h4>
    <div class="ui info message">
      All below images are generated with Russian Roulette enabled.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_1.png">
          <h5 class="ui center aligned container">1 Ray Sample Per Pixel</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_2.png">
          <h5 class="ui center aligned container">2 Ray Samples Per Pixel</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_4.png">
          <h5 class="ui center aligned container">4 Ray Samples Per Pixel</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_8.png">
          <h5 class="ui center aligned container">8 Ray Samples Per Pixel</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_64.png">
          <h5 class="ui center aligned container">64 Ray Samples Per Pixel</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-4_spheres_1024.png">
          <h5 class="ui center aligned container">1024 Ray Samples Per Pixel</h5>
        </div>
      </div>
    </div>

    <h3>Part 5: Adaptive Sampling</h3>
    <h4>[Part 5] Explanation and Walk Through on Adaptive Sampling</h4>
    <p>
      Adaptive sampling is a technique that can adaptively terminate the sampling process if we have enough confidence
      that the rendering of a given sample has converged.
    </p>
    <p>
      As for implementation details, I start with a couple of variables to keep track of the state of the sampling loop.
      <b>int i = 1</b>: integer i is the number of samples I've taken for the given pixel. It starts at 1 for easier
      calculation for mod and division. Then I have 2 double variables <b>s1</b> and <b>s2</b> to keep track of the
      accumulated sum and square sum of <b>Vector3D::illum</b>
    </p>
    <p>
      Then I start the loop, the majority of the inner-loop processing is the same as the previous parts. The difference
      is in each iteration, I calculate the illum of the result of <b>est_radiance_global_illumination</b>, and then add
      it to s1, and add its square value to s2. And then I check condition <b>i % samplesPerBatch == 0</b>. If this
      condition is true, I need to determine whether the sampling has converged so far, and we can stop the iteration early. To do
      that, I need to calculate the mean of the sampled results <b>double u = s1 / (double) i</b>, and the variance of
      the sampled results <b>double variance = (s2 - s1 * s1 / (double) i) / (i - 1)</b>. Then I need to calculate the
      value of variable <b>I</b> by <b>double I = 1.96 * (sqrt(variance) / sqrt((double) i))</b>. After this, I can then
      compare <b>I</b> and <b>maxTolerance * u</b>: if <b>I <= maxTolerance * u</b> is true, this means the sampling of
      this pixel has converged, and I can break the loop early. Otherwise, I just continue the loop util I reached the
      max number of samples specified.
    </p>
    <p>
      After I exit the loop, I need to modify the sample count to <b>i</b> (the actual number of samples I used in the
      loop) in <b>sampleBuffer.update_pixel</b> and <b>sampleCountBuffer</b>.
    </p>
    <h4>[Part 5] Images</h4>
    <div class="ui info message">
      All below images are generated with 2048 samples per pixel, 1 sample per light, and max ray depth as 5.
    </div>
    <div class="ui two column grid">
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-5_bunny.png">
          <h5 class="ui center aligned container">Image for CBbunny.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-5_bunny_rate.png">
          <h5 class="ui center aligned container">Rate for CBbunny.dae</h5>
        </div>
      </div>
      <div class="row">
        <div class="column ui segment">
          <img src="./assets/part-5_spheres.png">
          <h5 class="ui center aligned container">Image for CBspheres_lambertian.dae</h5>
        </div>
        <div class="column ui segment">
          <img src="./assets/part-5_spheres_rate.png">
          <h5 class="ui center aligned container">Rate for CBspheres_lambertian.dae</h5>
        </div>
      </div>
    </div>
    <br><br>
    <div class="ui right aligned container">
      <h5>
        Live version of this write-up is hosted at
        <a href="https://cal-cs184-student.github.io/project-webpages-sp23-xyuan195/proj3-1/index.html">
          https://cal-cs184-student.github.io/project-webpages-sp23-xyuan195/proj3-1/index.html
        </a>
      </h5>
      <br><br>
    </div>
  </div>
	</body>
</html>